{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✂️ Snorkel Intro Tutorial: _Data Slicing_\n",
    "> 정보 : 이 방법은 Slice-based Learning이라는 제목의 논문으로 [NeaurIPS 2019](https://arxiv.org/abs/1909.06349)에 accept되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 커뮤니케이션 가중 \n",
    "    - 상위 의사결정자와 의견이 \n",
    "- 방향성을 제시하지 못하고, 사소한걸 트집잡음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Don't truncate text fields in the display\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spam_dataset(load_train_labels: bool = False, split_dev_valid: bool = False):\n",
    "    filenames = sorted(glob.glob(\"data/Youtube*.csv\"))\n",
    "\n",
    "    dfs = []\n",
    "    for i, filename in enumerate(filenames, start=1):\n",
    "        df = pd.read_csv(filename)\n",
    "        # Lowercase column names\n",
    "        df.columns = map(str.lower, df.columns)\n",
    "        # Remove comment_id field\n",
    "        df = df.drop(\"comment_id\", axis=1)\n",
    "        # Add field indicating source video\n",
    "        df[\"video\"] = [i] * len(df)\n",
    "        # Rename fields\n",
    "        df = df.rename(columns={\"class\": \"label\", \"content\": \"text\"})\n",
    "        # Shuffle order\n",
    "        df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "        dfs.append(df)\n",
    "\n",
    "    df_train = pd.concat(dfs[:4])\n",
    "    df_dev = df_train.sample(100, random_state=123)\n",
    "\n",
    "    if not load_train_labels:\n",
    "        df_train[\"label\"] = np.ones(len(df_train[\"label\"])) * -1\n",
    "    df_valid_test = dfs[4]\n",
    "    df_valid, df_test = train_test_split(\n",
    "        df_valid_test, test_size=250, random_state=123, stratify=df_valid_test.label\n",
    "    )\n",
    "\n",
    "    if split_dev_valid:\n",
    "        return df_train, df_dev, df_valid, df_test\n",
    "    else:\n",
    "        return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = load_spam_dataset(load_train_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- slice function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from snorkel.slicing import slicing_function\n",
    "\n",
    "\n",
    "@slicing_function()\n",
    "def short_comment(x):\n",
    "    \"\"\"Ham comments are often short, such as 'cool video!'\"\"\"\n",
    "    return len(x.text.split()) < 5\n",
    "\n",
    "\n",
    "sfs = [short_comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 11817.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.slicing import slice_dataframe\n",
    "\n",
    "short_comment_df = slice_dataframe(df_test, short_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>super music﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I like shakira..﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>subscribe to my feed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Awesome ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Nice</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      text  label\n",
       "194  super music﻿           0    \n",
       "2    I like shakira..﻿      0    \n",
       "110   subscribe to my feed  1    \n",
       "263  Awesome ﻿              0    \n",
       "77   Nice                   0    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_comment_df[[\"text\", \"label\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a simple classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_features(vectorizer, df, split):\n",
    "    \"\"\"Convert pandas DataFrame containing spam data to bag-of-words PyTorch features.\"\"\"\n",
    "    words = [row.text for i, row in df.iterrows()]\n",
    "\n",
    "    if split == \"train\":\n",
    "        feats = vectorizer.fit_transform(words)\n",
    "    else:\n",
    "        feats = vectorizer.transform(words)\n",
    "    X = feats.todense()\n",
    "    Y = df[\"label\"].values\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "X_train, Y_train = df_to_features(vectorizer, df_train, \"train\")\n",
    "X_test, Y_test = df_to_features(vectorizer, df_test, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.001, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=0.001, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.utils import preds_to_probs\n",
    "\n",
    "preds_test = sklearn_model.predict(X_test)\n",
    "probs_test = preds_to_probs(preds_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set F1: 92.5%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(f\"Test set F1: {100 * f1_score(Y_test, preds_test):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store slice metadata in S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 16337.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.slicing import PandasSFApplier\n",
    "\n",
    "applier = PandasSFApplier(sfs)\n",
    "S_test = applier.apply(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.analysis import Scorer\n",
    "\n",
    "scorer = Scorer(metrics=[\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_comment</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     f1\n",
       "overall        0.925000\n",
       "short_comment  0.666667"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.score_slices(\n",
    "    S=S_test, golds=Y_test, preds=preds_test, probs=probs_test, as_dataframe=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체적으로 f1이 높지만 short_comment에 대해서는 f1이 낮네"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write additional slicing functions (SFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.slicing import SlicingFunction, slicing_function\n",
    "from snorkel.preprocess import preprocessor\n",
    "\n",
    "\n",
    "# Keyword-based SFs\n",
    "def keyword_lookup(x, keywords):\n",
    "    return any(word in x.text.lower() for word in keywords)\n",
    "\n",
    "\n",
    "def make_keyword_sf(keywords):\n",
    "    return SlicingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords),\n",
    "    )\n",
    "\n",
    "\n",
    "keyword_please = make_keyword_sf(keywords=[\"please\", \"plz\"])\n",
    "\n",
    "\n",
    "# Regex-based SFs\n",
    "@slicing_function()\n",
    "def regex_check_out(x):\n",
    "    return bool(re.search(r\"check.*out\", x.text, flags=re.I))\n",
    "\n",
    "\n",
    "@slicing_function()\n",
    "def short_link(x):\n",
    "    \"\"\"Returns whether text matches common pattern for shortened \".ly\" links.\"\"\"\n",
    "    return bool(re.search(r\"\\w+\\.ly\", x.text))\n",
    "\n",
    "\n",
    "# Leverage preprocessor in SF\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    return x\n",
    "\n",
    "\n",
    "@slicing_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return x.polarity > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 455.35it/s]\n"
     ]
    }
   ],
   "source": [
    "polarity_df = slice_dataframe(df_test, textblob_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Awesome ﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Shakira is the best dancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>OMG LISTEN TO THIS ITS SOO GOOD!! :D﻿</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Shakira is very beautiful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>awesome</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      text  label\n",
       "263  Awesome ﻿                              0    \n",
       "240  Shakira is the best dancer             0    \n",
       "261  OMG LISTEN TO THIS ITS SOO GOOD!! :D﻿  0    \n",
       "14   Shakira is very beautiful              0    \n",
       "114  awesome                                0    "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_df[[\"text\", \"label\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_sfs = [keyword_please, regex_check_out, short_link, textblob_polarity]\n",
    "\n",
    "sfs = [short_comment] + extra_sfs\n",
    "slice_names = [sf.name for sf in sfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 2635.51it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasSFApplier(sfs)\n",
    "S_test = applier.apply(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_comment</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_please</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_check_out</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_link</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_polarity</th>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         f1\n",
       "overall            0.925000\n",
       "short_comment      0.666667\n",
       "keyword_please     1.000000\n",
       "regex_check_out    1.000000\n",
       "short_link         0.500000\n",
       "textblob_polarity  0.727273"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scorer.score_slices(\n",
    "    S=S_test, golds=Y_test, preds=preds_test, probs=probs_test, as_dataframe=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "def get_pytorch_mlp(hidden_dim, num_layers):\n",
    "    layers = []\n",
    "    for _ in range(num_layers):\n",
    "        layers.extend([nn.Linear(hidden_dim, hidden_dim), nn.ReLU()])\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.slicing import SliceAwareClassifier\n",
    "\n",
    "# Define model architecture\n",
    "bow_dim = X_train.shape[1]\n",
    "hidden_dim = bow_dim\n",
    "mlp = get_pytorch_mlp(hidden_dim=hidden_dim, num_layers=2)\n",
    "\n",
    "# Initialize slice model\n",
    "slice_model = SliceAwareClassifier(\n",
    "    base_architecture=mlp,\n",
    "    head_dim=hidden_dim,\n",
    "    slice_names=[sf.name for sf in sfs],\n",
    "    scorer=scorer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1586/1586 [00:02<00:00, 543.45it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 2647.20it/s]\n"
     ]
    }
   ],
   "source": [
    "applier = PandasSFApplier(sfs)\n",
    "S_train = applier.apply(df_train)\n",
    "S_test = applier.apply(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.classification.data import DictDataset, DictDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_dataloader(X, Y, split, **kwargs):\n",
    "    \"\"\"Create a DictDataLoader for bag-of-words features.\"\"\"\n",
    "    ds = DictDataset.from_tensors(torch.FloatTensor(X), torch.LongTensor(Y), split)\n",
    "    return DictDataLoader(ds, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dl = create_dict_dataloader(X_train, Y_train, \"train\")\n",
    "train_dl_slice = slice_model.make_slice_dataloader(\n",
    "    train_dl.dataset, S_train, shuffle=True, batch_size=BATCH_SIZE\n",
    ")\n",
    "test_dl = create_dict_dataloader(X_test, Y_test, \"train\")\n",
    "test_dl_slice = slice_model.make_slice_dataloader(\n",
    "    test_dl.dataset, S_test, shuffle=False, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|██████████| 25/25 [00:01<00:00, 13.83it/s, model/all/train/loss=0.509, model/all/train/lr=0.0001]\n",
      "Epoch 1:: 100%|██████████| 25/25 [00:01<00:00, 14.95it/s, model/all/train/loss=0.263, model/all/train/lr=0.0001]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.classification import Trainer\n",
    "\n",
    "# For demonstration purposes, we set n_epochs=2\n",
    "trainer = Trainer(n_epochs=2, lr=1e-4, progress_bar=True)\n",
    "trainer.fit(slice_model, [train_dl_slice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>metric</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>task</td>\n",
       "      <td>SnorkelDataset</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.941704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>task_slice:short_comment_pred</td>\n",
       "      <td>SnorkelDataset</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>task_slice:keyword_please_pred</td>\n",
       "      <td>SnorkelDataset</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>task_slice:regex_check_out_pred</td>\n",
       "      <td>SnorkelDataset</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>task_slice:short_link_pred</td>\n",
       "      <td>SnorkelDataset</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>task_slice:textblob_polarity_pred</td>\n",
       "      <td>SnorkelDataset</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>task_slice:base_pred</td>\n",
       "      <td>SnorkelDataset</td>\n",
       "      <td>train</td>\n",
       "      <td>f1</td>\n",
       "      <td>0.941704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               label         dataset  split metric     score\n",
       "0  task                               SnorkelDataset  train  f1     0.941704\n",
       "1  task_slice:short_comment_pred      SnorkelDataset  train  f1     0.769231\n",
       "2  task_slice:keyword_please_pred     SnorkelDataset  train  f1     0.977778\n",
       "3  task_slice:regex_check_out_pred    SnorkelDataset  train  f1     1.000000\n",
       "4  task_slice:short_link_pred         SnorkelDataset  train  f1     0.500000\n",
       "5  task_slice:textblob_polarity_pred  SnorkelDataset  train  f1     0.800000\n",
       "6  task_slice:base_pred               SnorkelDataset  train  f1     0.941704"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_model.score_slices([test_dl_slice], as_dataframe=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
